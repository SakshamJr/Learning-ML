{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrsak\\AppData\\Local\\Temp\\ipykernel_7276\\639108302.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.TotalCharges = pd.to_numeric(df1.TotalCharges)\n",
      "C:\\Users\\jrsak\\AppData\\Local\\Temp\\ipykernel_7276\\639108302.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.replace('No internet service','No',inplace=True)\n",
      "C:\\Users\\jrsak\\AppData\\Local\\Temp\\ipykernel_7276\\639108302.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.replace('No phone service','No',inplace=True)\n",
      "C:\\Users\\jrsak\\AppData\\Local\\Temp\\ipykernel_7276\\639108302.py:62: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df1[col].replace({\"Yes\": 1, \"No\": 0}, inplace=True)\n",
      "C:\\Users\\jrsak\\AppData\\Local\\Temp\\ipykernel_7276\\639108302.py:62: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df1[col].replace({\"Yes\": 1, \"No\": 0}, inplace=True)\n",
      "C:\\Users\\jrsak\\AppData\\Local\\Temp\\ipykernel_7276\\639108302.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[col].replace({\"Yes\": 1, \"No\": 0}, inplace=True)\n",
      "C:\\Users\\jrsak\\AppData\\Local\\Temp\\ipykernel_7276\\639108302.py:63: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df1.replace({'Male':1,'Female':0},inplace = True)\n",
      "C:\\Users\\jrsak\\AppData\\Local\\Temp\\ipykernel_7276\\639108302.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.replace({'Male':1,'Female':0},inplace = True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\jrsak\\\\OneDrive\\\\Documents\\\\MachineLearning\\\\codebasics\\\\Datasets\\\\churn.csv')\n",
    "df.sample(5)\n",
    "\n",
    "\n",
    "# %%\n",
    "df.drop('customerID', axis = 1, inplace=True)\n",
    "\n",
    "# %%\n",
    "df.dtypes\n",
    "\n",
    "# %% [markdown]\n",
    "# # TotalCharges is object\n",
    "\n",
    "# %%\n",
    "pd.to_numeric(df.TotalCharges, errors='coerce').isnull()\n",
    "\n",
    "# %%\n",
    "df[pd.to_numeric(df.TotalCharges, errors='coerce').isnull()]\n",
    "\n",
    "# %%\n",
    "df1 = df[df['TotalCharges']!=' ']\n",
    "\n",
    "# %%\n",
    "df1.shape\n",
    "\n",
    "# %%\n",
    "df1.dtypes\n",
    "\n",
    "# %%\n",
    "df1.TotalCharges = pd.to_numeric(df1.TotalCharges)\n",
    "\n",
    "# %%\n",
    "df1.TotalCharges.dtype\n",
    "\n",
    "# %%\n",
    "df1.dtypes\n",
    "\n",
    "# %%\n",
    "def print_unique_col_values(df):\n",
    "    for col in df:\n",
    "        if df[col].dtypes == \"object\":\n",
    "            print(f\"{col} :\\t {df[col].unique()}\")\n",
    "# No internet service = No\n",
    "# No phone service = No\n",
    "df1.replace('No internet service','No',inplace=True)\n",
    "df1.replace('No phone service','No',inplace=True)\n",
    "yes_no_columns = [\n",
    "    \"Partner\",\n",
    "    \"Dependents\",\n",
    "    \"PhoneService\",\n",
    "    \"MultipleLines\",\n",
    "    \"OnlineSecurity\",\n",
    "    \"OnlineBackup\",\n",
    "    \"DeviceProtection\",\n",
    "    \"TechSupport\",\n",
    "    \"StreamingTV\",\n",
    "    \"StreamingMovies\",\n",
    "    \"PaperlessBilling\",\n",
    "    \"Churn\",\n",
    "]\n",
    "for col in yes_no_columns:\n",
    "    df1[col].replace({\"Yes\": 1, \"No\": 0}, inplace=True)\n",
    "df1.replace({'Male':1,'Female':0},inplace = True)\n",
    "df2 = pd.get_dummies(data=df1,columns=['InternetService','Contract','PaymentMethod'])\n",
    "cols_to_scale = ['tenure','MonthlyCharges','TotalCharges']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])\n",
    "X = df2.drop('Churn',axis = 1)\n",
    "y = df2.Churn\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=10\n",
    ")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Input(shape=(26,)),\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        keras.layers.Dense(16, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train,epochs = 25)\n",
    "\n",
    "\n",
    "model.evaluate(X_test,y_test)\n",
    "\n",
    "y_p = model.predict(X_test)\n",
    "y_pred = []\n",
    "for el in y_p:\n",
    "    if el > 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "y_pred[:10]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                  precision    recall  f1-score   support\n",
    "\n",
    "#             0       0.86      0.88      0.87      1046\n",
    "#             1       0.63      0.60      0.62       361\n",
    "\n",
    "#     accuracy                            0.81      1407\n",
    "#    macro avg        0.75      0.74      0.74      1407\n",
    "# weighted avg        0.80      0.81      0.81      1407"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0, count_class_1 = df2.Churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0, count_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing Dataframe into separate classes\n",
    "df_class_0 = df2[df2[\"Churn\"] == 0]\n",
    "df_class_1 = df2[df2[\"Churn\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0_sampled = df_class_0.sample(count_class_1)\n",
    "df_class_0_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_sampled = pd.concat([df_class_1, df_class_0_sampled], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test_sampled.drop('Churn',axis=1)\n",
    "y = df_test_sampled.Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=10, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sampled = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Input(shape=(26,)),\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        keras.layers.Dense(16, activation=\"relu\"),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model_sampled.compile(\n",
    "    optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model_sampled.fit(X_train, y_train, epochs=25)\n",
    "y_p_sampled = model_sampled.predict(X_test)\n",
    "y_pred_sampled = []\n",
    "for el in y_p_sampled:\n",
    "    if el > 0.5:\n",
    "        y_pred_sampled.append(1)\n",
    "    else:\n",
    "        y_pred_sampled.append(0)\n",
    "y_pred[:10]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_sampled = classification_report(y_test, y_pred_sampled)\n",
    "print(cr_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                   Without Sampling\n",
    "\n",
    "#                  precision    recall  f1-score   support\n",
    "\n",
    "#             0       0.86      0.88      0.87      1046\n",
    "#             1       0.63      0.60      0.62       361\n",
    "\n",
    "#     accuracy                            0.81      1407\n",
    "#    macro avg        0.75      0.74      0.74      1407\n",
    "# weighted avg        0.80      0.81      0.81      1407"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2: Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0, count_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1_oversampled = df_class_1.sample(count_class_0, replace=True)\n",
    "df_oversampled = pd.concat([df_class_1_oversampled, df_class_0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oversampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_oversampled.drop('Churn',axis=1)\n",
    "y = df_oversampled.Churn\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=10, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_over = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Input(shape=(26,)),\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        keras.layers.Dense(16, activation=\"relu\"),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model_over.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model_over.fit(X_train, y_train, epochs=25)\n",
    "y_p_over = model_over.predict(X_test)\n",
    "y_pred_over = []\n",
    "for el in y_p_over:\n",
    "    if el > 0.5:\n",
    "        y_pred_over.append(1)\n",
    "    else:\n",
    "        y_pred_over.append(0)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_over = classification_report(y_test, y_pred_over)\n",
    "print(cr_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 3: SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(sampling_strategy='minority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    1046\n",
       "1     361\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    4117\n",
       "1    1508\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sampled, y_train_sampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "1    4117\n",
       "0    4117\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_sampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6667 - loss: 0.5991\n",
      "Epoch 2/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7874 - loss: 0.4629\n",
      "Epoch 3/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7842 - loss: 0.4546\n",
      "Epoch 4/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7933 - loss: 0.4481\n",
      "Epoch 5/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7965 - loss: 0.4401\n",
      "Epoch 6/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7916 - loss: 0.4414\n",
      "Epoch 7/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8071 - loss: 0.4222\n",
      "Epoch 8/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.4321\n",
      "Epoch 9/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8061 - loss: 0.4310\n",
      "Epoch 10/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8066 - loss: 0.4277\n",
      "Epoch 11/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8067 - loss: 0.4285\n",
      "Epoch 12/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8166 - loss: 0.4157\n",
      "Epoch 13/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8234 - loss: 0.4086\n",
      "Epoch 14/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.4016\n",
      "Epoch 15/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8188 - loss: 0.4091\n",
      "Epoch 16/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8229 - loss: 0.3986\n",
      "Epoch 17/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8285 - loss: 0.3997\n",
      "Epoch 18/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8309 - loss: 0.3907\n",
      "Epoch 19/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8276 - loss: 0.3904\n",
      "Epoch 20/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8257 - loss: 0.4020\n",
      "Epoch 21/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8306 - loss: 0.3918\n",
      "Epoch 22/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8280 - loss: 0.3947\n",
      "Epoch 23/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.3703\n",
      "Epoch 24/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.3707\n",
      "Epoch 25/25\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8321 - loss: 0.3860\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83      1046\n",
      "           1       0.53      0.68      0.60       361\n",
      "\n",
      "    accuracy                           0.76      1407\n",
      "   macro avg       0.70      0.74      0.71      1407\n",
      "weighted avg       0.79      0.76      0.77      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_smote = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Input(shape=(26,)),\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        keras.layers.Dense(16, activation=\"relu\"),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model_smote.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model_smote.fit(X_train_sampled, y_train_sampled, epochs=25)\n",
    "y_p_smote = model_smote.predict(X_test)\n",
    "y_pred_smote = []\n",
    "for el in y_p_smote:\n",
    "    if el > 0.5:\n",
    "        y_pred_smote.append(1)\n",
    "    else:\n",
    "        y_pred_smote.append(0)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_smote = classification_report(y_test, y_pred_smote)\n",
    "print(cr_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
